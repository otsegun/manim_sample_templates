1
00:00:00,000 --> 00:00:03,650
Imagine you’re the manager of a company that owns a number of factories,

2
00:00:03,650 --> 00:00:07,600
each of which can produce one of at most two products.

3
00:00:07,600 --> 00:00:11,683
You’d like your company to produce all possible unique products to maximize profit,

4
00:00:11,683 --> 00:00:13,666
but determining how to do this by hand

5
00:00:13,666 --> 00:00:16,733
would be tedious at best and impossible at worst

6
00:00:16,733 --> 00:00:18,050
how can you do this efficiently?

7
00:00:19,766 --> 00:00:25,083
One way of doing so would be to formulate it in terms of the boolean satisfiability problem (or SAT for short).

8
00:00:25,866 --> 00:00:29,383
SAT is the problem of satisfying a boolean formula in CNF,

9
00:00:29,383 --> 00:00:31,233
which is a conjunction of clauses,

10
00:00:31,233 --> 00:00:34,950
each of which being a disjunction of positive and negative literals.

11
00:00:35,916 --> 00:00:38,800
An easy way to think of it is that you have groups of literals

12
00:00:38,800 --> 00:00:40,933
and at least one from each group has to be satisfied.

13
00:00:42,050 --> 00:00:46,883
For this example, one such assignment is setting a, d and e to 1

14
00:00:46,883 --> 00:00:49,616
(so their negations are 0) and the rest to anything.

15
00:00:50,950 --> 00:00:57,183
Going back to the factories problem, each product will be a clause and each factory producing it a literal.

16
00:00:57,183 --> 00:01:01,950
If a factory produces a single product, it will be added to the appropriate clause.

17
00:01:01,950 --> 00:01:08,100
If it produces two, one will be positive and one negative, since a factory can only produce one product at a time.

18
00:01:09,450 --> 00:01:15,083
As you can see, a product is produced if and only if at least one of its factories are producing it.

19
00:01:15,083 --> 00:01:20,583
In this simple example, the problem doesn’t have a solution, because a single factory produces two unique products.

20
00:01:22,050 --> 00:01:28,683
SAT runs in exponential time and so solving it for a large number of factories and products could take a few millennia.

21
00:01:28,683 --> 00:01:32,900
One thing we could do in cases like these is to use an approximation algorithm,

22
00:01:32,900 --> 00:01:37,683
which exchanges an improved running time for a solution that is close to, but not quite the optimum.

23
00:01:38,950 --> 00:01:42,383
Interestingly, one of SAT’s best approximation algorithms

24
00:01:42,383 --> 00:01:46,950
is a random combination of two of its other, worse approximation algorithms,

25
00:01:46,950 --> 00:01:49,733
which is, in my opinion, remarkable.

26
00:01:49,733 --> 00:01:51,283
So.. let’s start approximating!

27
00:01:52,800 --> 00:01:57,700
As previously mentioned, SAT is the problem of satisfying a boolean formula in CNF.

28
00:01:57,700 --> 00:02:02,333
This formulation can’t really be approximated, since the satisfying assignment either exists

29
00:02:02,333 --> 00:02:04,766
or it doesn’t, as we’ve seen in the factories problem.

30
00:02:05,983 --> 00:02:08,383
We’ll therefore generalize SAT to MAX-SAT,

31
00:02:08,383 --> 00:02:11,333
which will no longer require that every group is satisfied,

32
00:02:11,333 --> 00:02:13,283
but instead that as many as possible are.

33
00:02:14,216 --> 00:02:19,116
In this case, by setting the literals like so, three out of four clauses can be satisfied!

34
00:02:21,483 --> 00:02:25,050
Our first algorithm to solve MAX-SAT will be entirely random,

35
00:02:25,050 --> 00:02:27,733
assigning true and false values with the probability of 1/2.

36
00:02:28,833 --> 00:02:32,616
I wrote a Python program to simulate it on the expression from before.

37
00:02:32,616 --> 00:02:37,516
We have a generate_random_values function that randomly generates n boolean values.

38
00:02:37,516 --> 00:02:42,333
We then have a count_satisfied_clauses function that counts the number of satisfied clauses of the expression.

39
00:02:43,783 --> 00:02:45,716
Running 10 000 times in total,

40
00:02:45,716 --> 00:02:50,150
we randomly assign boolean values to the literals and count the number of satisfied clauses,

41
00:02:50,150 --> 00:02:51,850
printing the satisfied percentage at the end.

42
00:02:53,600 --> 00:02:54,833
If we run the program,

43
00:02:54,833 --> 00:02:59,750
we see that the average number of satisfied clauses for this expression is about 56 %,

44
00:02:59,750 --> 00:03:02,816
which is pretty good, considering how simple the algorithm is

45
00:03:02,816 --> 00:03:05,750
and that the best it can do in this case is 75 %.

46
00:03:07,750 --> 00:03:09,716
Looking at the algorithm more formally,

47
00:03:09,083 --> 00:03:14,200
RAND-SAT doesn’t satisfy a clause of k literals if and only if all of them are set to false,

48
00:03:14,200 --> 00:03:16,816
the probability of which is is (1/2)^k.

49
00:03:17,550 --> 00:03:22,433
Therefore the probability that it its satisfied is 1 − (1/2)^k.

50
00:03:23,300 --> 00:03:25,650
Since each clause contains at least one literal,

51
00:03:25,650 --> 00:03:29,033
it is satisfied with the probability of at least 1/2,

52
00:03:29,033 --> 00:03:33,966
meaning the algorithm will (in expectation) satisfy at least 1/2 of the clauses.

53
00:03:35,583 --> 00:03:40,333
Our second algorithm, LP-SAT, will be a little more complicated.

54
00:03:40,333 --> 00:03:43,766
To fully understand it, we need a slight interlude about linear programming.

55
00:03:44,916 --> 00:03:50,483
A linear program conains real variables and linear inequalities that restrict them.

56
00:03:50,483 --> 00:03:54,316
The goal is to maximize a linear expression (called the objective function).

57
00:03:55,583 --> 00:03:58,800
Using Python and its package PULP to solve this particular example,

58
00:03:58,800 --> 00:04:02,916
the optimal solution yields the following objective function and assignment of variables.

59
00:04:04,050 --> 00:04:08,483
Since linear programming is polynomial, we’ll use it to solve MAX-SAT.

60
00:04:08,483 --> 00:04:13,500
Taking our familiar expression, we’ll convertit to a linear program in the following way.

61
00:04:13,500 --> 00:04:17,700
We’ll create abinary variable for each literal and clause in the formula.

62
00:04:17,700 --> 00:04:21,149
The 
expression to maximize will be the sum of clause variables,

63
00:04:21,149 --> 00:04:23,516
which corresponds to the number of satisfied clauses.

64
00:04:24,350 --> 00:04:29,983
The inequalities will reflect the clauses: we’ll restrict the clause variables by the formula variables,

65
00:04:29,983 --> 00:04:31,616
depending on the clause literals.

66
00:04:32,500 --> 00:04:36,166
If we, for example, take a look at the third inequality,

67
00:04:36,166 --> 00:04:41,100
the only way for y to be 1 is if at least one of the literal variables are satisfied

68
00:04:41,100 --> 00:04:44,200
(so either b is 1 or c is 0).

69
00:04:44,200 --> 00:04:48,533
If none of them are, then the right side will be 0, forcing y to be 0 as well.

70
00:04:49,450 --> 00:04:52,250
Running the program yields the objective function of 3,

71
00:04:52,250 --> 00:04:56,566
meaning that only three of the four clauses can be satisfied (which we already know)

72
00:04:57,433 --> 00:05:02,116
At first glance, it seems like we’ve created a fast exact algorithm for MAX-SAT,

73
00:05:02,116 --> 00:05:04,033
but that’s only because we cheated

74
00:05:04,033 --> 00:05:08,200
arbitrarily setting the variables to be integers (binary, to be more specific)

75
00:05:08,200 --> 00:05:10,916
makes linear programming exponential, so this won’t work.

76
00:05:12,066 --> 00:05:13,466
Well, let’s fix it.

77
00:05:13,466 --> 00:05:15,316
Writing the linear program formally,

78
00:05:15,316 --> 00:05:18,233
we have binary variables for literals and clauses,

79
00:05:18,233 --> 00:05:19,733
inequalities for each clause

80
00:05:19,733 --> 00:05:21,900
and an objective function as the sum of clause variables.

81
00:05:22,966 --> 00:05:25,633
Since the problem is the variables being integer,

82
00:05:25,633 --> 00:05:28,616
let’s just relax them to allow real numbers (from 0 to 1).

83
00:05:29,416 --> 00:05:31,683
This will make the linear program fast again,

84
00:05:31,683 --> 00:05:33,583
but it won’t be solving MAX-SAT anymore,

85
00:05:33,583 --> 00:05:36,116
since the variables can now be any number from 0 to 1.

86
00:05:37,466 --> 00:05:42,850
We can demonstrate this on the following expression, constructing this relaxed linear program.

87
00:05:42,383 --> 00:05:47,650
The optimum is 2.5, with a and b both set to 0.5.

88
00:05:47,650 --> 00:05:50,333
Now we obviously can’t satisfy two and a half clauses,

89
00:05:50,333 --> 00:05:56,950
but what we can do is use a and b to help us assign true and false values to the corresponding literals.

90
00:05:56,966 --> 00:06:04,583
Since the variable a is 0.5, we’ll assign the literal a true with this probability and false

91
00:06:04,583 --> 00:06:05,650
otherwise and the same for b.

92
00:06:06,766 --> 00:06:09,750
This is the core idea behind LP-SAT

93
00:06:09,750 --> 00:06:12,750
we have an assign_variables_based_on_lp function

94
00:06:12,750 --> 00:06:16,500
which returns boolean values for each literal based on this exact idea,

95
00:06:16,500 --> 00:06:19,033
with the rest of the program being the same as RAND-SAT.

96
00:06:20,616 --> 00:06:21,766
Running the program,

97
00:06:21,766 --> 00:06:26,266
we see that the average number of satisfied clauses for this expression is about 66 %.

98
00:06:29,100 --> 00:06:30,483
For this part of the video,

99
00:06:30,483 --> 00:06:34,766
I present a proof for how well LP-SAT performs on the size of the clauses

100
00:06:34,766 --> 00:06:36,100
(same as we’ve done for RAND-SAT).

101
00:06:37,050 --> 00:06:40,783
It is a little technical, so if you aren’t sure about some of its steps,

102
00:06:40,783 --> 00:06:43,533
don’t worry too much – the conclusion is what matters most.

103
00:06:44,700 --> 00:06:47,733
For the proof, we’ll use the following two facts.

104
00:06:47,733 --> 00:06:51,350
Fact A is the inequality of arithmetic and geometric means,

105
00:06:51,350 --> 00:06:54,783
which states that for any sequence of non-negative real numbers,

106
00:06:54,783 --> 00:06:58,016
the geometric mean is less than or equal to the arithmetic mean.

107
00:06:59,700 --> 00:07:02,116
Fact B is Jensen’s inequality,

108
00:07:02,116 --> 00:07:06,016
which states that if a function is concave on the interval [0, 1],

109
00:07:06,016 --> 00:07:09,133
f(0) = a and f(1) = a + b,

110
00:07:09,133 --> 00:07:10,683
then the following inequality holds.

111
00:07:12,250 --> 00:07:14,900
It actually has this simple geometric interpretation,

112
00:07:14,900 --> 00:07:16,500
feel free to pause here and think it through.

113
00:07:19,000 --> 00:07:22,733
If you recall, this is the relaxed linear program we used as hints for LP-SAT

114
00:07:23,733 --> 00:07:27,400
Now consider the optimal solution of the relaxed linear program

115
00:07:27,400 --> 00:07:29,233
and a clause containing k_j literals.

116
00:07:30,083 --> 00:07:31,650
For it to not be satisfied,

117
00:07:31,650 --> 00:07:37,300
LP-SAT has to decide that all its positive literals be false and its negative literals be true,

118
00:07:37,300 --> 00:07:39,400
the probability of which is the following product.

119
00:07:40,183 --> 00:07:43,150
Using fact A, the products turn into sums,

120
00:07:43,150 --> 00:07:45,333
which can further be turned into the following expression.

121
00:07:46,366 --> 00:07:49,150
Now you can notice that the expression in the parentheses

122
00:07:49,150 --> 00:07:52,183
is just the j-th inequality, so we can simplify in the following way.

123
00:07:54,000 --> 00:07:57,016
Now let’s calculate the probability that it is satisfied.

124
00:07:57,016 --> 00:08:01,283
If we take it as a function of z_j^*, we can observe that f(0) = 0

125
00:08:00,533 --> 00:08:05,750
and that it is concave (by checking that the second derivative is positive).

126
00:08:05,750 --> 00:08:08,866
This means that we can use Jensen’s inequality and get this bound.

127
00:08:10,050 --> 00:08:14,566
As k_j goes to infinity, the highlighted expression gets larger and larger,

128
00:08:14,566 --> 00:08:19,050
converging to the well-known constant of 1/e, which is approximately 0.63.

129
00:08:20,116 --> 00:08:22,150
This is exactly what we wanted,

130
00:08:22,150 --> 00:08:27,516
because the expected number of satisfied clauses is equal to the sum of the probabilities that they are satisfied,

131
00:08:27,516 --> 00:08:30,000
which, using our inequality, yields the following.

132
00:08:31,150 --> 00:08:34,366
Taking the constant out, we get the sum of clause variables,

133
00:08:34,366 --> 00:08:37,233
which is the objective function and so the optimum,

134
00:08:37,233 --> 00:08:43,850
meaning that the algorithm satisfies (in expectation) at least (1 − 1/e) clauses of the optimum.

135
00:08:43,850 --> 00:08:46,100
This is better, but still not quite there.

136
00:08:48,883 --> 00:08:50,983
Looking at both RAND-SAT and LP-SAT,

137
00:08:50,983 --> 00:08:57,366
the probability that a clause with k_j literals is satisfied is at least the following for each respective algorithms.

138
00:08:57,366 --> 00:09:04,266
As a reminder, z_j^* is a number between 0 and 1, which tells us how well can the clause be satisfied in the optimal case

139
00:09:04,266 --> 00:09:05,883
(the sum of z_j^* being the optimum).

140
00:09:06,833 --> 00:09:10,750
Since it’s less than 1, we’ll add it to RAND-SAT too for easier calculations.

141
00:09:12,033 --> 00:09:15,583
Let’s look at how the algorithms perform on clauses of varying size.

142
00:09:15,583 --> 00:09:20,133
As you can see, RAND-SAT seems to be performing better the larger the clause is.

143
00:09:20,133 --> 00:09:26,283
This is no surprise, since the more variables there are, the higher chance is for RAND-SAT to pick one correctly.

144
00:09:26,283 --> 00:09:29,950
On the other hand, LP-SAT performs worse the larger the clause is,

145
00:09:29,950 --> 00:09:33,133
ultimately converging to the constant we arrived at during the proof.

146
00:09:33,883 --> 00:09:36,200
This prompts an intersting idea

147
00:09:36,200 --> 00:09:40,533
since RAND-SAT performs better for longer clauses and LP-SAT performs better for shorter ones,

148
00:09:40,533 --> 00:09:42,483
let’s just average them.

149
00:09:42,483 --> 00:09:44,166
And thus BEST-SAT is born.

150
00:09:44,166 --> 00:09:49,050
It works by randomly deciding to use either RAND-SAT or LP-SAT for each clause independently.

151
00:09:49,850 --> 00:09:52,716
Substituting the bound for larger k's of LP-SAT

152
00:09:52,716 --> 00:09:56,833
and calculating the probabilities for BEST-SAT by averaging RAND-SAT and LP-SAT,

153
00:09:56,833 --> 00:10:00,183
we see that it is at least 3/4 the optimum for each k.

154
00:10:00,850 --> 00:10:05,233
This means that BEST-SAT satisfies at least 3/4 of the clauses as the optimum,

155
00:10:05,233 --> 00:10:08,550
which is just wild, considering how bad the to individual algorithms are.

156
00:10:12,016 --> 00:10:15,416
I really hope you enjoyed this video, as it took a while to make

157
00:10:15,416 --> 00:10:19,166
and hope it inspired you to further explore the wonderful world of approximation algorithms.

